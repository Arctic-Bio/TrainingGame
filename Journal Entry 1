##(This does not represent my normal writing style, these journals are what I concot during late nights when my mind is going a million miles a minute.)##

I want this all as one simple algorithm please, a sort of master control algorithm that looks through data and finds causality chains and episodic periodic and continual events and classifies all present and how they impact the system. Again the goal of AGI is to learn the rules of the game and not the game itself, its training should be on how to understand rules, games, how to find them, because optimization tasks are easy once we have the parameters, the goal of it is to find its own parameters.

While AI attempts to optimize a system based off of averages or common relations AGi has to learn the rules of any game it encounters, it must be taught how to teach, learn how to learn, it must learn the rules and concepts of anything presented to it, it does this by having one goal, separating  this into many concepts needed to achieve it given an adaptive environment. It must be able to create concepts of events, states, causality, and so on, like episodic states, continual states, linear changes, so on. The goal is a system that finds out what is important in every scenario and adapts itself to function with that by knowing the rules. Think of a video game like pacman where the goal is maximize points and minimize paths for ghosts to get to you and maximize escape paths. We have two very easy ways of scoring that, knowing the ghost position and the balls, and also what each looks like, and moves, and how they move. We gain a concept of all the areas they can go and walls and limitations and that the white orbs add points and touching a ghost subtracts. We do classification knowing that walls cannot move and our limited range of movement, we start the game by identifying the rules of it, as long as we can do that we can optimize it and create a perfect system or close to it. AGI should not learn levels, it should learn the rules that optimize all levels, it should learn mechanics, a system that learns the game not the level, it teaches itself what to do from basic goals, like the points maximization, and then learns how each thing affects it such as touching hosts, or not moving, it should learn that distance from ghosts matters, states matters, how the ghosts move, and that it needs to maximize points eaten while minimizing ghost routes, but it should learn all of that on its own over play time, true adaptation. Also we should give it just the states and positions of each piece, nothing else. It should have the same understanding that a human being would of it. It should have reference over time of movement, periodic or episodic, any changes, or relations, or causes and effects or interactions. I need it to take note of that and solve it to the best off its abilities doing what I nicknamed the breadcrumb method. 

Breadcrumb means that we take a goal, perhaps score maximization, then we have it go through and observe to see how things interact (With an understanding of random events as well and how it may be forced to adapt on the fly) we then have it create micro goals more or less which are rules that it comes up with from its experience, such as “Never touch ghosts” but of course in the abstract mathematical way not in words or semantics. With these general rules it can continue to play the game adaptively no matter the level, setup, or amount of ghosts or location of power ups or whatnot, it simply learns what rules are most important and what elements to pay attention to. We are teaching it how to learn and how to teach itself.

General intelligence must be able to generalize!!!
